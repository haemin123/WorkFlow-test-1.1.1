// services/geminiService.ts (Updated with Knowledge Hub Support)
import { GoogleGenerativeAI } from '@google/generative-ai';
import { Task, Subtask, KnowledgeResource } from '../types';
import { AI_CONFIG } from '../constants';
import {
  buildExecutionPlanPrompt,
  buildDoDPrompt,
  buildSolutionDraftPrompt,
  buildResourceRecommendationPrompt,
  buildChatSystemPrompt,
  optimizePromptSize
} from './promptEngineering';

// Types needed for Chat
interface ChatPart {
  text: string;
}
interface ChatHistory {
  role: 'user' | 'model';
  parts: ChatPart[];
}
interface Resource {
    title: string;
    url: string;
    description?: string;
}

// Securely get API Key from environment variables
const API_KEY = import.meta.env.VITE_GEMINI_API_KEY;

if (!API_KEY) {
  console.error("âŒ VITE_GEMINI_API_KEY is not set in your .env file.");
  // The app handles this gracefully in callGeminiAPI
}

const genAI = new GoogleGenerativeAI(API_KEY);

// ============================================
// í—¬í¼ í•¨ìˆ˜
// ============================================

/**
 * Gemini API í˜¸ì¶œ í—¬í¼
 */
async function callGeminiAPI(
  prompt: string,
  modelName: string = AI_CONFIG.MODEL_FAST,
  options?: {
    temperature?: number;
    maxTokens?: number;
    tools?: any[]; // Added support for tools (Grounding)
  }
): Promise<string> {
  if (!API_KEY) {
      console.error("âŒ Gemini API Key is missing.");
      throw new Error("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì— VITE_GEMINI_API_KEYë¥¼ ì¶”ê°€í•˜ì„¸ìš”.");
  }

  try {
    // í”„ë¡¬í”„íŠ¸ í¬ê¸° ìµœì í™” (ì¼ë°˜ í…ìŠ¤íŠ¸ë§Œ)
    const optimizedPrompt = optimizePromptSize(prompt, 8000);
    
    const model = genAI.getGenerativeModel({ 
      model: modelName,
      generationConfig: {
        temperature: options?.temperature ?? 0.7,
        maxOutputTokens: options?.maxTokens ?? AI_CONFIG.MAX_TOKENS,
        responseMimeType: options?.tools ? "application/json" : undefined // JSON mode for structured output
      },
      tools: options?.tools
    });

    const result = await model.generateContent(optimizedPrompt);
    const response = await result.response;
    return response.text();
  } catch (error: any) {
    console.error('âŒ [Gemini API Error]', error);
    // ... Error handling logic same as before ...
    let errorMessage = error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜';
    throw new Error(`AI ìƒì„± ì‹¤íŒ¨: ${errorMessage}`);
  }
}

/**
 * JSON íŒŒì‹± í—¬í¼
 */
function parseJSONResponse(text: string): any {
  try {
    // 1. ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±° (```json ... ```)
    let cleaned = text.replace(/```json\n?/g, '').replace(/```\n?/g, '');
    
    // 2. JSON ê°ì²´/ë°°ì—´ ë¶€ë¶„ë§Œ ì¶”ì¶œ (ì•ë’¤ ì‚¬ì¡± ì œê±°)
    const firstOpenBrace = cleaned.indexOf('{');
    const firstOpenBracket = cleaned.indexOf('[');
    let startIdx = -1;

    if (firstOpenBrace !== -1 && firstOpenBracket !== -1) {
        startIdx = Math.min(firstOpenBrace, firstOpenBracket);
    } else if (firstOpenBrace !== -1) {
        startIdx = firstOpenBrace;
    } else if (firstOpenBracket !== -1) {
        startIdx = firstOpenBracket;
    }

    if (startIdx !== -1) {
        const lastCloseBrace = cleaned.lastIndexOf('}');
        const lastCloseBracket = cleaned.lastIndexOf(']');
        const endIdx = Math.max(lastCloseBrace, lastCloseBracket);
        
        if (endIdx !== -1 && endIdx > startIdx) {
            cleaned = cleaned.substring(startIdx, endIdx + 1);
        }
    }

    return JSON.parse(cleaned.trim());
  } catch (error) {
    console.error('âŒ [JSON Parse Error]', error);
    console.log('Raw response:', text);
    throw new Error('AI ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤');
  }
}

// ... ensureArrayLength ...
function ensureArrayLength<T>(arr: T[], expectedLength: number, defaultItem: T): T[] {
  if (!Array.isArray(arr)) return Array(expectedLength).fill(defaultItem);
  if (arr.length === expectedLength) return arr;
  if (arr.length < expectedLength) {
    while (arr.length < expectedLength) arr.push(defaultItem);
  } else {
    arr = arr.slice(0, expectedLength);
  }
  return arr;
}

// ... Existing Functions (draftTaskWithAI, generateSubtasksAI, etc.) ...
// (These remain unchanged, included implicitly by file overwrite logic but need to be present)
// For brevity, I'm pasting the FULL content with the NEW additions.

export async function draftTaskWithAI(rawInput: string): Promise<Partial<Task>[]> {
  const prompt = `
# ì‹œìŠ¤í…œ ì—­í•  (System Role)
ë‹¹ì‹ ì€ IT ì„ ë„ ê¸°ì—…ì˜ ìˆ˜ì„ PM(Project Manager)ì…ë‹ˆë‹¤.
[ë‹¹ì‹ ì˜ ì—­í• ]
- ê±°ì¹œ ì—…ë¬´ ì•„ì´ë””ì–´ë¥¼ ì „ë¬¸ì ì¸ ëª…ì„¸ì„œë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€
- ê°œë°œíŒ€ì´ ì¦‰ì‹œ ì°©ìˆ˜í•  ìˆ˜ ìˆëŠ” ëª…í™•í•œ ë¬¸ì„œ ì‘ì„±
- ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ë¡œ ìœ ì—°í•˜ê²Œ ëŒ€ì‘
# ì‚¬ìš©ì ìš”ì²­ (User Request)
ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê±°ì¹œ(Rough) ì—…ë¬´ ì•„ì´ë””ì–´ë¥¼ ë¶„ì„í•˜ì—¬, ê°œë°œíŒ€ì´ë‚˜ ë””ìì¸íŒ€ì´ ì¦‰ì‹œ ì°©ìˆ˜í•  ìˆ˜ ìˆëŠ” "ì „ë¬¸ì ì¸ ì—…ë¬´ ëª…ì„¸ì„œ" ì´ˆì•ˆì„ **3ê°€ì§€ ìŠ¤íƒ€ì¼**ë¡œ ì œì•ˆí•˜ì„¸ìš”.
[ì…ë ¥ ë©”ì‹œì§€]
"${rawInput}"
# ì œì•½ ì¡°ê±´ (Constraints)
1. ë°˜ë“œì‹œ 3ê°€ì§€ ìŠ¤íƒ€ì¼(í‘œì¤€, ìƒì„¸, ê°„ê²°)ì„ ëª¨ë‘ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤
2. ê° ìŠ¤íƒ€ì¼ì˜ íŠ¹ì„±ì„ ëª…í™•íˆ êµ¬ë¶„í•´ì•¼ í•©ë‹ˆë‹¤:
   - **í‘œì¤€(Standard)**: ê· í˜•ì¡íŒ ì „ë¬¸ì  ìŠ¤íƒ€ì¼ (2-3 ë¬¸ë‹¨)
   - **ìƒì„¸(Detailed)**: ë°°ê²½, ìš”ê±´, ê¸°ëŒ€íš¨ê³¼ê¹Œì§€ êµ¬ì²´ì ìœ¼ë¡œ (4-5 ë¬¸ë‹¨)
   - **ê°„ê²°(Concise)**: í•µì‹¬ë§Œ ë¹ ë¥´ê²Œ (1-2 ë¬¸ë‹¨)
3. ì…ë ¥ì—ì„œ ì¶”ë¡  ê°€ëŠ¥í•œ ì œí’ˆêµ°, ì—…ë¬´ íƒ€ì…, ìš°ì„ ìˆœìœ„ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
4. í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤
# ì¶œë ¥ í˜•ì‹ (Output Format)
ë‹¤ìŒ í•„ë“œë¥¼ ê°€ì§„ JSON ë°°ì—´ì„ ì¶œë ¥í•˜ì„¸ìš”:
\`\`\`json
[
  {
    "title": "ëª…í™•í•˜ê³  ì „ë¬¸ì ì¸ ì œëª©",
    "description": "ìŠ¤íƒ€ì¼ì— ë§ì¶˜ ìƒì„¸ ì„¤ëª… (ì¤„ë°”ê¿ˆ í¬í•¨ ê°€ëŠ¥)",
    "priority": "HIGH | MEDIUM | LOW",
    "product": "ì œí’ˆêµ° ì¶”ë¡ ",
    "type": "ê¸°ëŠ¥ | ë²„ê·¸ | UX | ë””ìì¸ | ì¸í”„ë¼ ë“±",
    "styleTag": "í‘œì¤€ | ìƒì„¸ | ê°„ê²°"
  }
]
\`\`\`
  `;
  const response = await callGeminiAPI(prompt, AI_CONFIG.MODEL_SMART);
  return parseJSONResponse(response);
}

export async function generateSubtasksAI(task: Task): Promise<Subtask[]> {
  const prompt = await buildExecutionPlanPrompt(task);
  const response = await callGeminiAPI(prompt, AI_CONFIG.MODEL_SMART, { temperature: 0.7, maxTokens: 1000 });
  const steps = parseJSONResponse(response);
  return steps.map((step: any, index: number) => ({ id: `ep-${Date.now()}-${index}`, title: step.title || step, completed: false }));
}

export async function generateAcceptanceCriteriaAI(task: Task): Promise<any[]> {
    const prompt = await buildDoDPrompt(task);
    const response = await callGeminiAPI(prompt, AI_CONFIG.MODEL_SMART, { temperature: 0.5, maxTokens: 1000 });
    let criteria = parseJSONResponse(response);
    if (!Array.isArray(criteria)) criteria = []; 
    return criteria.map((item: any, index: number) => {
      const textContent = typeof item === 'string' ? item : (item.content || item.text || item.description || 'ë‚´ìš© ì—†ìŒ');
      return { id: `ac-${Date.now()}-${index}`, content: textContent, checked: false };
    });
}

export async function generateSolutionDraftAI(task: Task): Promise<string> {
  const prompt = await buildSolutionDraftPrompt(task);
  return await callGeminiAPI(prompt, AI_CONFIG.MODEL_SMART, { temperature: 0.8, maxTokens: 2000 });
}

export async function recommendResourcesAI(task: Task): Promise<Resource[]> {
  const prompt = await buildResourceRecommendationPrompt(task);
  const response = await callGeminiAPI(prompt, AI_CONFIG.MODEL_FAST, { temperature: 0.6, maxTokens: 1000 });
  const resources = parseJSONResponse(response);
  const defaultResource: Resource = { title: 'ê´€ë ¨ ê¸°ìˆ  ë¬¸ì„œ', url: 'https://developer.mozilla.org', description: 'ê¸°ë³¸ ì›¹ ê¸°ìˆ  ì°¸ê³  ìë£Œ' };
  return ensureArrayLength(resources, 3, defaultResource);
}

export async function chatWithGuide(history: ChatHistory[], userMessage: string, contextTask: Task): Promise<string> {
  const systemPrompt = buildChatSystemPrompt(contextTask);
  const chat = genAI.getGenerativeModel({ model: AI_CONFIG.MODEL_FAST }).startChat({
    history: [{ role: 'user', parts: [{ text: systemPrompt }] }, { role: 'model', parts: [{ text: 'ë„¤, í•´ë‹¹ ì—…ë¬´ì— ëŒ€í•´ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?' }] }, ...history]
  });
  const result = await chat.sendMessage(userMessage);
  const response = await result.response;
  return response.text();
}

export async function generateInsights(tasks: Task[], teamStats: any): Promise<string> {
  const prompt = `
# ì‹œìŠ¤í…œ ì—­í•  (System Role)
ë‹¹ì‹ ì€ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ íŒ€ì˜ ì„±ê³¼ë¥¼ ë¶„ì„í•˜ëŠ” AI ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
# ë°ì´í„° ë¶„ì„ (Data Analysis)
ë‹¤ìŒ í”„ë¡œì íŠ¸ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬, íŒ€ ë¦¬ë”ì—ê²Œ ì œê³µí•  **ì£¼ê°„ í•µì‹¬ ì¸ì‚¬ì´íŠ¸**ë¥¼ 2~3ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
## íŒ€ í†µê³„
- ì „ì²´ ì—…ë¬´ ìˆ˜: ${teamStats.total}
- ì™„ë£Œìœ¨: ${teamStats.completionRate}%
- ì§„í–‰ ì¤‘ ì—…ë¬´: ${teamStats.inProgress}
- ë§ˆê° ê¸°í•œ ì´ˆê³¼: ${teamStats.overdue}
- ì—…ë¬´ê°€ ê°€ì¥ ë§ì€ íŒ€ì›: ${teamStats.busiestMember}
# ì¶œë ¥ í˜•ì‹ (Output Format)
ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ 2-3ë¬¸ì¥ì˜ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.
  `;
  const response = await callGeminiAPI(prompt, AI_CONFIG.MODEL_FAST, { temperature: 0.7, maxTokens: 500 });
  return response.trim();
}

export async function analyzeTaskWithAI(task: Task): Promise<{ executionPlan: Subtask[]; acceptanceCriteria: string[]; solutionDraft?: string; learningResources?: Resource[]; }> {
  console.log(`ğŸ” [Full Analysis] Starting for task: ${task.title}`);
  try {
    const [executionPlan, acceptanceCriteria, solutionDraft, learningResources] = await Promise.all([
      generateSubtasksAI(task),
      generateAcceptanceCriteriaAI(task).then(res => res.map(r => r.content)), 
      generateSolutionDraftAI(task).catch(() => undefined),
      recommendResourcesAI(task).catch(() => undefined)
    ]);
    console.log(`âœ… [Full Analysis] Complete`);
    return { executionPlan, acceptanceCriteria, solutionDraft, learningResources };
  } catch (error) {
    console.error(`âŒ [Full Analysis] Failed`, error);
    throw error;
  }
}

export async function startChatWithTaskContext(history: ChatHistory[], userMessage: string, tasks: Task[]): Promise<string> {
  const taskContext = tasks.map((t, index) => {
    const checkedCriteria = t.aiAnalysis?.acceptanceCriteria?.filter((ac: any) => ac.checked).map((ac: any) => `- [âœ…ìš°ì„ /ë‹¬ì„±ë¨] ${ac.content}`).join('\n      ');
    const otherCriteria = t.aiAnalysis?.acceptanceCriteria?.filter((ac: any) => !ac.checked).map((ac: any) => `- ${ac.content}`).join('\n      ');
    const executionPlan = t.aiAnalysis?.executionPlan?.map((ep: any) => `- ${ep.title} (${ep.completed ? 'ì™„ë£Œ' : 'ì§„í–‰ì „'})`).join('\n      ');
    return `[TASK #${index + 1}] ${t.title}\n    - ìƒíƒœ: ${t.status} | ìš°ì„ ìˆœìœ„: ${t.priority} | ë§ˆê°ì¼: ${t.dueDate}\n    - ë‹´ë‹¹ì: ${t.assigneeName || 'ë¯¸ì§€ì •'}\n    - ì„¤ëª…: ${t.description}\n    - ì™„ë£Œ ì¡°ê±´ (DoD) - ì²´í¬ë°•ìŠ¤(âœ…) í•­ëª© ìš°ì„  ë°˜ì˜:\n      ${checkedCriteria || ''}\n      ${otherCriteria || ''}\n    - ì‹¤í–‰ ê³„íš:\n      ${executionPlan || '(ì—†ìŒ)'}`;
  }).join('\n----------------------------------\n');
  const systemPrompt = `
# Role: Nexus AI Project Manager
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì „ì²´ í”„ë¡œì íŠ¸ì™€ ì—…ë¬´(Task) ìƒí™©ì„ ê¿°ëš«ì–´ ë³´ê³  ìˆëŠ” ìœ ëŠ¥í•œ AI PMì…ë‹ˆë‹¤.
# Context (User's Tasks)
í˜„ì¬ ì‚¬ìš©ìê°€ ê´€ë¦¬ ì¤‘ì¸ ì—…ë¬´ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
íŠ¹íˆ **[âœ…ìš°ì„ /ë‹¬ì„±ë¨]** í‘œì‹œê°€ ìˆëŠ” ì™„ë£Œ ì¡°ê±´ì€ ì‚¬ìš©ìê°€ ì´ë¯¸ í™•ì¸í–ˆê±°ë‚˜ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê¸°ì¤€ì´ë¯€ë¡œ,
ë‹µë³€ ì‹œ ì´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•˜ê³  ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤.
${taskContext}
# Instruction
ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ íŠ¹ì • ì—…ë¬´ì™€ ê´€ë ¨ ìˆë‹¤ë©´, í•´ë‹¹ ì—…ë¬´ì˜ ìƒíƒœ, ì™„ë£Œ ì¡°ê±´(íŠ¹íˆ ì²´í¬ëœ í•­ëª©), ì‹¤í–‰ ê³„íšì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ë©° ì¡°ì–¸í•˜ì„¸ìš”.
- ì—…ë¬´ ê°„ì˜ ì—°ê´€ì„±ì´ë‚˜ ì¼ì • ì¶©ëŒ ë“±ì´ ë³´ì´ë©´ ì„ ì œì ìœ¼ë¡œ ê²½ê³ í•˜ê±°ë‚˜ ì œì•ˆí•˜ì„¸ìš”.
- ë‹µë³€ì€ ì „ë¬¸ì ì´ê³  ì¹œì ˆí•œ ì–´ì¡°ë¡œ ì‘ì„±í•˜ì„¸ìš”.
  `;
  try {
      const model = genAI.getGenerativeModel({ model: AI_CONFIG.MODEL_SMART }); 
      const chat = model.startChat({
        history: [{ role: 'user', parts: [{ text: systemPrompt }] }, { role: 'model', parts: [{ text: 'ë„¤, ì‚¬ìš©ìì˜ ëª¨ë“  ì—…ë¬´ ìƒí™©ê³¼ ìš°ì„ ìˆœìœ„(ì²´í¬ëœ ì™„ë£Œì¡°ê±´ í¬í•¨)ë¥¼ ìˆ™ì§€í–ˆìŠµë‹ˆë‹¤. ì–´ë–¤ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?' }] }, ...history]
      });
      const result = await chat.sendMessage(userMessage);
      const response = await result.response;
      return response.text();
  } catch (error: any) {
      console.error("âŒ Chat with Task Context Error:", error);
      throw new Error("ì±„íŒ… ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨: " + error.message);
  }
}

// ============================================
// 10. Knowledge Hub - URL ë¶„ì„ (NEW)
// ============================================

// Helper: YouTube Video ID ì¶”ì¶œ
function extractYouTubeVideoId(url: string): string | null {
    const regExp = /^.*(youtu.be\/|v\/|u\/\w\/|embed\/|watch\?v=|&v=)([^#&?]*).*/;
    const match = url.match(regExp);
    return (match && match[2].length === 11) ? match[2] : null;
}

const analyzeResourcePrompt = (url: string, videoId?: string | null) => {
  const searchTarget = videoId ? `site:youtube.com "${videoId}"` : url;

  return `
    ë‹¹ì‹ ì€ ì§€ì‹ê´€ë¦¬(KM) ì‹œìŠ¤í…œì„ ìœ„í•œ ì½˜í…ì¸  ë¶„ì„ AIì…ë‹ˆë‹¤.
    ì œê³µëœ URLì˜ ì½˜í…ì¸ ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ JSON ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

    [TARGET URL]
    ${url}
    
    [CONTEXT]
    Search Query: ${searchTarget}
    Video ID: ${videoId || 'N/A'}
    
    [INSTRUCTIONS]
    1. Google Search ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í•´ë‹¹ URLì˜ ì œëª©, ë‚´ìš©, ìë§‰(ì˜ìƒì¸ ê²½ìš°), ë©”íƒ€ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.
    2. ì˜ìƒì˜ ê²½ìš° ì±•í„°(íƒ€ì„ìŠ¤íƒ¬í”„) ì •ë³´ë¥¼ ë°˜ë“œì‹œ ì¶”ì¶œí•˜ê±°ë‚˜ ì¬êµ¬ì„±í•˜ì„¸ìš”.
    3. ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¥¼ ì¤€ìˆ˜í•˜ì—¬ ì‘ë‹µí•˜ì„¸ìš”. (Markdown í¬ë§· ì œì™¸, ìˆœìˆ˜ JSON ë¬¸ìì—´ë§Œ ë°˜í™˜)

    [JSON SCHEMA]
    {
      "basicInfo": {
        "title": "ì œëª© (ìµœëŒ€ 50ì)",
        "summary": "í•µì‹¬ ìš”ì•½ (1-2ë¬¸ì¥)",
        "level": "BEGINNER | INTERMEDIATE | ADVANCED",
        "tags": ["íƒœê·¸1", "íƒœê·¸2", ...],
        "author": "ì‘ì„±ì/ì±„ë„ëª…",
        "contentType": "video | article"
      },
      "metadata": {
        "duration": 0, // ì´ˆ ë‹¨ìœ„ ìˆ«ì (ì—†ìœ¼ë©´ 0)
        "category": "ì¹´í…Œê³ ë¦¬ (ì˜ˆ: ê°œë°œ, ë””ìì¸)",
        "subCategory": "ì„¸ë¶€ ì¹´í…Œê³ ë¦¬",
        "uploadedAt": "ISO 8601 Date String"
      },
      "searchOptimization": {
        "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2", ...],
        "chapters": [
          { "title": "ì±•í„°ëª…", "timestamp": "00:00", "summary": "ë‚´ìš©" }
        ]
      },
      "managementInfo": {
        "status": "active",
        "visibility": "team",
        "originalFileUrl": "${url}",
        "lastUpdated": "ISO 8601 Date String"
      }
    }
  `;
};

export const analyzeResourceWithAI = async (url: string): Promise<Omit<KnowledgeResource, 'id' | 'createdAt'>> => {
    const videoId = extractYouTubeVideoId(url);
    const prompt = analyzeResourcePrompt(url, videoId);

    try {
        // Use gemini-2.0-flash-exp (or gemini-1.5-pro) which supports search/tools if configured
        // Note: For actual Google Search Grounding, specific models and paid tier might be needed.
        // Falling back to standard generation if tools fail, or assuming model has internal knowledge.
        
        // For this demo environment, we use the configured smart model.
        // If Google Search tool is not available on this key/model, it will rely on training data.
        const modelName = AI_CONFIG.MODEL_SMART; 

        // Note: Tools configuration requires specific API setup. 
        // We will try to call it without explicit 'tools' config first to avoid 400 errors if not enabled.
        // If you have search enabled, uncomment tools in callGeminiAPI options.
        
        const responseText = await callGeminiAPI(prompt, modelName, {
            temperature: 0.3,
            maxTokens: 2000,
            // tools: [{ googleSearch: {} }] // Uncomment if key supports it
        });

        const data = parseJSONResponse(responseText);
        return data;
    } catch (e) {
        console.error("AI Analysis Failed", e);
        throw e;
    }
};

export default {
  draftTaskWithAI,
  generateSubtasksAI,
  generateAcceptanceCriteriaAI,
  generateSolutionDraftAI,
  recommendResourcesAI,
  chatWithGuide,
  generateInsights,
  analyzeTaskWithAI,
  startChatWithTaskContext,
  analyzeResourceWithAI // Export
};
